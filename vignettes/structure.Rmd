---
title: "Structure"
output: rmarkdown::html_document
vignette: >
  %\VignetteIndexEntry{Structure}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
knitr:
  opts_chunk:
    collapse: true
    comment: '#>'
params:
  tool: "Tool1"
  workflow: "Workflow1"
  pkg: "nemo"
---

```{css, echo=FALSE}
/*
https://github.com/r-lib/pkgdown/issues/2721
Correct flex boxes from sizing based upon the largest in tabset
*/

.tab-content>.tab-pane {
  display: none;
}

.tab-content>.active {
  display: block;
}
```

```{r params_eval, echo=FALSE, eval=FALSE}
params <- list(
  tool = "Tool1",
  workflow = "Workflow1",
  pkg = "nemo"
)
```

```{r pkgs, message=FALSE, warning=FALSE, echo=FALSE}
{
  use(params$pkg)
  use("dplyr")
  use("glue", "glue")
  use("purrr", "map")
  use("readr", "read_tsv")
  use("tibble", "tibble")
  use("tidyr", "unnest")
  use("fs", "dir_info")
  use("knitr", "kable")
}
```


```{r}
#| label: opts
#| echo: false
options(width = 100)
```

{nemo} is built on top of R's [R6] encapsulated object-oriented programming
implementation, which helps with code organisation. It consists of several base
classes like `Config`, `Tool`, and `Workflow` which we describe below.
Each R6 class can contain public and private functions and non-functions (fields).

Other R packages like {[tidywigits]} and {[dracarys]} can create their own `Tool` and
`Workflow` children classes that inherit (or override) functions from
the {nemo} parent classes. This allows for custom parsers and tidiers for specific
bioinformatic tools and workflows.

[R6]: <https://github.com/r-lib/R6> "R6 package repo"
[tidywigits]: <https://github.com/umccr/tidywigits> "tidywigits"
[dracarys]: <https://github.com/umccr/dracarys> "dracarys"

Here we use the `Tool1` and `Workflow1` classes as examples to illustrate the
structure of the package.

## `Config`

A `Config` object contains functionality for interacting with YAML
configuration files (under `inst/config`) that specify the schemas, types,
patterns and field descriptions for the _raw_ input _files_ and _tidy_ output
_tbls_. See `?Config`.

### raw {.tabset .tabset-pills}

#### intro

Let's look at some of the information for the raw `Tool1` config, for instance:

```{r tool1_config1}
tool <- params$tool
workflow <- params$workflow
conf <- Config$new(tool, pkg = "nemo")
conf
```

You can access the individual fields in the classic R list-like manner, using
the `$` sign.

#### patterns

Patterns are used to fish out the relevant files from a directory listing.

```{r tool1_config_raw_patterns}
conf$get_raw_patterns() |>
  knitr::kable(caption = glue("{tool} raw file patterns."))
```

#### descriptions

File descriptions are based on the available open source documentation.

```{r tool1_config_raw_descriptions}
conf$get_raw_descriptions() |>
  knitr::kable(caption = glue("{tool} raw file descriptions."))
```

#### versions

Versions are used to distinguish changes in schema between individual tool
versions. For example, after `Tool1` v1.2.3 metrics Y and Z were added to `table1`,
which is reflected in the available schemas.
For now we are using `latest` as a default version based on the most
recent schema tests, and any discrepancies we see are labelled accordingly by the
version of the tool that generated a file with a different schema.

```{r tool1_config_raw_versions}
conf$get_raw_versions() |>
  knitr::kable(caption = glue("{tool} raw file versions."))
```


#### schemas

The raw schemas specify the column name and type (e.g. character (`c`),
integer (`i`), float/double (`d`)) for each input file:

```{r tool1_config_raw_schemas1}
(s <- conf$get_raw_schemas_all())
s |>
  dplyr::filter(name == "table1", version == "v1.2.3") |>
  dplyr::select("schema") |>
  tidyr::unnest("schema")
```

### tidy {.tabset .tabset-pills}

#### intro

Now let's look at some of the information in the tidy `Tool1` config. The
difference between raw and tidy configs is mostly in the column names (they are
standardised to lowercase separated by underscores, i.e. `snake_case`), and some
raw files get split into multiple tidy tables (e.g. for normalisation purposes).

#### descriptions

Tidy descriptions are the same as the raw descriptions for now.

```{r tool1_config_tidy_descriptions}
conf$get_tidy_descriptions() |>
  knitr::kable(caption = glue("{tool} tidy file descriptions."))
```

#### schemas

```{r tool1_config_tidy_schemas1}
(s <- conf$get_tidy_schemas_all())
s |>
  dplyr::filter(.data$name == "table1", version == "v1.2.3") |>
  dplyr::select("schema") |>
  tidyr::unnest("schema")
```

## `Tool` {.tabset .tabset-pills}

`Tool` is the main organisation class for all file parsers and tidiers.
It contains functions for parsing and tidying typical CSV/TSV files (with
column names), and TXT files where the column names are missing. Currently it
utilises the very simple `readr::read_delim` function from the {[readr]} package
that reads all the data into memory. See `?Tool`.

These simple parsers are used in 80-90% of cases, so in the future we can
optimise the parsing if needed with faster packages such as {[data.table]},
{[duckdb-r]}/{[duckplyr]} or {[r-polars]}.

[readr]: <https://github.com/tidyverse/readr> "readr"
[duckdb-r]: <https://github.com/duckdb/duckdb-r> "duckdb-r"
[duckplyr]: <https://github.com/tidyverse/duckplyr> "duckplyr"
[data.table]: <https://github.com/Rdatatable/data.table> "data.table"
[r-polars]: <https://github.com/pola-rs/r-polars> "r-polars"

### initialise

We can have different `Tool` children classes that inherit (or override) functions
and fields from the `Tool` parent class.
For example, we can create a `Tool` object for `Tool1` as follows:

- Initialise a `Tool1` object:

```{r tool_tool1}
tool1_path <- system.file("extdata/tool1", package = "nemo")
t1 <- nemo::Tool1$new(path = tool1_path)
# each class comes with a print function
t1
```

### config

- Its `Config` object is also constructed based on the `name` supplied - this
is used internally to find files of interest and infer their schemas:

```{r tool1_conf}
t1$config
t1$config$get_raw_patterns()
t1$config$get_raw_schema("table1", v = "v1.2.3")
# t1$config$get_raw_schema("table1", v = "latest") # default
t1$config$get_tidy_schema("table1", v = "v1.2.3")
# t1$config$get_tidy_schema("table1", v = "latest") # default
```

### list

We can list files that can be parsed with `list_files()`:

```{r tool1_list}
(lf <- t1$list_files())
lf |> dplyr::slice(1) |> str()
```

### tidy

We can parse and tidy files of interest using the `tidy` function. Note
that this function is called on the object and not assigned anywhere:

```{r tool1_tidy}
# this will create a new field tbls containing the tidy data (and optionally
# the 'raw' parsed data)
t1$tidy(tidy = TRUE, keep_raw = TRUE)
t1$tbls
t1$tbls$raw[[1]] |> dplyr::glimpse()
# the tidy tibbles are nested to allow for more than one tidy tibble per file
t1$tbls$tidy[[1]][["data"]][[1]] |> dplyr::glimpse()
```

### filter

We can also focus on a subset of files to tidy using the `filter_files()` function.
The `include` and `exclude` arguments can specify which parsers to include or
exclude in the analysis:

```{r tool1_filter}
# create new Tool1 object
t2 <- nemo::Tool1$new(path = tool1_path)
t2$files
t2$filter_files(include = c("tool1_table2", "tool1_table3"))
t2$files
```

### write

After tidying the data of interest, we can write the tidy tibbles to various
formats, like Apache Parquet, PostgreSQL, CSV/TSV and R's RDS.
Below we can see that the `id` specified is added to the written files in
an additional `nemo_id` column. This can be used e.g. to distinguish results
from different runs in a data pipeline.
When writing to a database like PostgreSQL, another column `nemo_pfix` is used
to distinguish results from the same run from the same tool.

```{r tool1_write}
t2$tidy() # first need to tidy
outdir1 <- tempdir()
fmt <- "csv"
t2$write(diro = outdir1, format = fmt, input_id = "run123")
wfiles <- fs::dir_info(outdir1) |> dplyr::select(1:5)
wfiles |>
  dplyr::mutate(bname = basename(.data$path)) |>
  dplyr::select("bname", "size", "type")
# readr::read_csv(wfiles$path[1], show_col_types = F) # see bug #137
```

### nemofy

The `nemofy` function is a convenient wrapper for the process of filtering,
tidying, and writing.

```{r nemofy1}
t3 <- nemo::Tool1$new(path = tool1_path)
outdir2 <- file.path(tempdir(), "t3") |> fs::dir_create()
t3$files
t3$nemofy(
  diro = outdir2,
  format = "tsv",
  input_id = "run_t3"
)
wfiles2 <- fs::dir_info(outdir2) |>
  dplyr::mutate(bname = basename(.data$path))
wfiles2 |>
  dplyr::select("bname", "size", "type")
readr::read_tsv(wfiles2$path[2], show_col_types = F)
```

## `Workflow`

A `Workflow` consists of a list of one or more `Tool`s. We can construct a
certain `Workflow` with different `Tool`s, which would allow parsing and writing
tidy tables from a variety of bioinformatic tools. See `?Workflow`.

For example, {nemo} contains a `Workflow1` class as a `Workflow` child (containing
only a single `Tool1` for simplicity). Similarly to `Tool`, a `Workflow` object
contains functions such as `filter_files`, `list_files`, `tidy`, `write` and
`nemofy`:

```{r w1_init}
w <- system.file("extdata/tool1", package = "nemo") |>
  nemo::Workflow1$new()
outdir3 <- file.path(tempdir(), "oa") |> fs::dir_create()
w$list_files()
x <- w$nemofy(
  diro = outdir3,
  format = "tsv",
  input_id = "workflow1_run1"
)
wfiles3 <- fs::dir_info(outdir3) |>
  dplyr::select(1:5) |>
  dplyr::mutate(bname = basename(.data$path))
wfiles3 |>
  dplyr::select("bname", "size", "type")
readr::read_tsv(wfiles3$path[1], show_col_types = F)
```
